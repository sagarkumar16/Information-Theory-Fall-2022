{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Time Series Generator\n",
    "\n",
    "X = np.random.randint(low=0,high=2,size=(3,1000))\n",
    "\n",
    "X[2,:] = X[0,:] & X[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analysis:\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        # number of variables\n",
    "        self.nvars = np.shape(data)[0]\n",
    "\n",
    "        # length\n",
    "        self.duration = np.shape(data)[1]\n",
    "\n",
    "        # determine the joint alphabet\n",
    "        vars = np.arange(0,self.nvars)\n",
    "        alphabet = np.unique(data[vars,:],axis=1)\n",
    "\n",
    "        # calculate the joint distribution\n",
    "        self.P = pd.DataFrame(sparse.csc_matrix((np.shape(alphabet)[1],1)),index=pd.MultiIndex.from_arrays(alphabet))\n",
    "\n",
    "        self.P.index.names = vars\n",
    "        self.P.rename({0:'joint'}, axis='columns', inplace=True)\n",
    "        \n",
    "        for a in self.P.index:\n",
    "\n",
    "            self.P.loc[a] = np.count_nonzero(np.all((data[vars,:]==np.reshape(np.array(a),(-1,1))),axis=0),axis=0)\n",
    "\n",
    "        self.P['joint'] = self.P.joint.values/np.sum(self.P.joint.values)\n",
    "\n",
    "\n",
    "    # calculate the marginal distribution of one variable or a higher-order marginal of several variables\n",
    "    def marginal_distribution(self,x):\n",
    "\n",
    "        return self.P.groupby(level=x).sum().rename({'joint':'marginal'}, axis='columns')\n",
    "\n",
    "    \n",
    "    # return a conditional distribution of one or several variables given one or several other variables\n",
    "    def conditional_distribution(self,x,y):\n",
    "\n",
    "        xy = tuple(list(set(x).union(set(y))))\n",
    "\n",
    "        # Calculate the joint distribution of x and y\n",
    "        p_xy = self.marginal_distribution(xy)\n",
    "        p_xy.rename({'marginal':'joint'}, axis='columns', inplace=True)\n",
    "        p_xy.reset_index(inplace=True)\n",
    "        \n",
    "        # Calculate the marginal of the conditioning variable\n",
    "        p_y = self.marginal_distribution(y)\n",
    "        p_y.reset_index(inplace=True)\n",
    "\n",
    "        p_xcy = p_xy.merge(p_y, left_on=y, right_on=y)\n",
    "\n",
    "        p_xcy['conditional'] = p_xcy['joint']/p_xcy['marginal']\n",
    "        p_xcy.set_index(list(xy), inplace=True)\n",
    "\n",
    "        return p_xcy[['conditional']]\n",
    "\n",
    "    # Calculate the entropy of one or more variables\n",
    "    def entropy(self,var=None):\n",
    "\n",
    "        if np.all(var==None):\n",
    "\n",
    "            p = self.P['joint'][self.P['joint'].ne(0)].values.astype('float')\n",
    "\n",
    "        else:\n",
    "\n",
    "            p = self.P.groupby(level=var).sum().values\n",
    "        \n",
    "        return -np.sum(p*np.log2(p))\n",
    "\n",
    "\n",
    "    # Conditional Entropy\n",
    "    def conditional_entropy(self,x,y):\n",
    "\n",
    "        xy = list(set(x).union(set(y)))\n",
    "\n",
    "        H_XY = self.entropy(xy)\n",
    "        H_Y  = self.entropy(y)\n",
    "\n",
    "        return H_XY  - H_Y\n",
    "        \n",
    "    # Mutual Information\n",
    "    def mutual_information(self,x,y):\n",
    "\n",
    "        xy = list(set(x).union(set(y)))\n",
    "\n",
    "        H_X = self.entropy(x)\n",
    "        H_Y = self.entropy(y)\n",
    "\n",
    "        H_XY = self.entropy(xy)\n",
    "\n",
    "        return H_X + H_Y - H_XY\n",
    "    \n",
    "\n",
    "    # Interaction Information\n",
    "    def interaction_information(self):\n",
    "\n",
    "        II = 0\n",
    "\n",
    "        vars = np.arange(0,self.nvars)\n",
    "\n",
    "        for n_subset in range(1,self.nvars+1):\n",
    "\n",
    "            for subset in [list(sub) for sub in itertools.combinations(vars, r=n_subset)]:\n",
    "\n",
    "                II += (-1)**(self.nvars-n_subset+1)*self.entropy(subset)\n",
    "\n",
    "\n",
    "        return II\n",
    "\n",
    "\n",
    "    # total correlation\n",
    "    def total_correlation(self):\n",
    "\n",
    "        vars = list(range(0,self.nvars))\n",
    "\n",
    "        HS = self.entropy(vars)\n",
    "\n",
    "        HX = np.sum([self.entropy([x]) for x in vars])\n",
    "\n",
    "        return HX - HS\n",
    "\n",
    "\n",
    "    # dual total correlation\n",
    "    def dual_total_correlation(self):\n",
    "\n",
    "        vars = np.arange(0,self.nvars)\n",
    "\n",
    "        HS = self.entropy(list(vars))\n",
    "\n",
    "        HX = np.sum([self.entropy(list(vars[vars!=x])) for x in vars])\n",
    "\n",
    "        return HX - (self.nvars-1)*HS\n",
    "\n",
    "\n",
    "    # redundancy synergy index\n",
    "    def redundancy_synergy_index(self,source,target):\n",
    "\n",
    "        I_joint = self.mutual_information(source,target)\n",
    "\n",
    "        I_ind =  np.sum([self.mutual_information([x],target) for x in source])\n",
    "\n",
    "        return I_joint - I_ind\n",
    "\n",
    "    \n",
    "    # varadans synergy\n",
    "    def varadans_synergy(self,source, target, source_partitions):\n",
    "\n",
    "        I_joint = self.mutual_information(source,target)\n",
    "\n",
    "        I_max = max([sum([self.mutual_information(p,target) for p in partition]) for partition in source_partitions])\n",
    "\n",
    "        return I_joint - I_max\n",
    "\n",
    "\n",
    "    # Delta I\n",
    "    def delta_I(self,x,y):\n",
    "\n",
    "        # Calculate the empirical joint, conditional and y-marginal\n",
    "        p = self.conditional_distribution(x,y)[['joint','conditional']]\n",
    "        p.rename({'joint':'xy','conditional':'x|y'}, axis='columns', inplace=True)\n",
    "\n",
    "        # blow up the index to all possible values\n",
    "        temp = pd.DataFrame(index=pd.MultiIndex.from_product([np.unique(p.index.get_level_values(level=i)) for i in [*x,*y]]))\n",
    "        temp.index.names = [*x,*y]\n",
    "        p = pd.merge(temp, p, left_index=True, right_index=True, how='left')\n",
    "        p = p.fillna(0)\n",
    "\n",
    "        temp = self.marginal_distribution(y).rename({'marginal':'y'}, axis='columns')\n",
    "        p = pd.merge(p.reset_index(), temp.reset_index(), left_on=y, right_on=y, how='left')\n",
    "        p.set_index([*x,*y], inplace=True)\n",
    "\n",
    "\n",
    "        # Calculate the distribution of each xi conditioned on y\n",
    "        for xi in x:\n",
    "\n",
    "            p_xicy = self.conditional_distribution([xi],y)[['conditional']]\n",
    "            p_xicy.rename({'conditional':'x'+str(xi)+'|y'}, axis='columns', inplace=True)\n",
    "            \n",
    "            p = pd.merge(p.reset_index(), p_xicy.reset_index(), left_on=[xi,*y], right_on=[xi,*y], how='left')\n",
    "            p.set_index([*x,*y], inplace=True)\n",
    "\n",
    "        # Calculate the conditional distribution of x given y under the independent model\n",
    "        p['ind_x|y'] = np.ones(p.shape[0])\n",
    "\n",
    "        for xi in x:\n",
    "\n",
    "            p.loc[:,'ind_x|y'] *= p.loc[:,'x'+str(xi)+'|y']\n",
    "            p.drop(['x'+str(xi)+'|y'], axis='columns' ,inplace=True)\n",
    "\n",
    "        # Calculate the evidence for x under the independent model\n",
    "        temp = (p['ind_x|y']*p['y']).to_frame()\n",
    "        temp = temp.groupby(level=x).sum()\n",
    "        temp.rename({0:'ind_x'}, axis='columns', inplace=True)\n",
    "\n",
    "        p = pd.merge(p.reset_index(), temp.reset_index(), left_on=x, right_on=x, how='left')\n",
    "        p.set_index([*x,*y], inplace=True)\n",
    "\n",
    "        # Calculate y|x with Bayes' theorem\n",
    "        p['ind_y|x'] = p['ind_x|y']*p['y']/p['ind_x']\n",
    "\n",
    "        # Calculate y|x under the data\n",
    "        temp = self.conditional_distribution(y,x)[['conditional']]\n",
    "        temp.rename({'conditional':'y|x'}, axis='columns', inplace=True)\n",
    "\n",
    "        # this merge drops all the x,y combinations that do not occur in the data\n",
    "        p = pd.merge(p, temp, right_index=True, left_index=True, how='right')\n",
    "\n",
    "        # Calculate a weighted difference\n",
    "        return np.nansum(p['xy'].values*np.log2(p['y|x'].values/p['ind_y|x']))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Analysis(X)\n",
    "x.conditional_distribution([0,1],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [[[0],[1,2]],\n",
    "              [[1],[0,2]],\n",
    "              [[2],[0,1]],\n",
    "              [[0],[1],[2]]]\n",
    "\n",
    "partitions = [[[0],[1]]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72520f3d33c0ce576a88d53c25b1bf9ee064aec902990a83ee9113ca6f7415c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
